# ğŸ¬ Hybrid Search System for Movie Dataset

This project implements a modular hybrid search pipeline on a 1M-row TMDB movie dataset using Qdrant as the vector database. It combines dense (semantic), sparse (keyword), and reranking techniques to provide high-quality, user-specific search results.

High-level, the code covers 3 scenarios (check out the demo video for more info):
- test pipeline on 3,000 dataset records to test end-to-end code (local database,localhost:6333)
- full pipeline on 1.2M records which takes several hours to load depending on your compute (production database on EC2 machine, localhost:8333)
- search notebook to provide bare-bones UX (configured to run on 1.2M records)


## ğŸš€ Features

- **Dense Vector Search** â€” using SentenceTransformers (`all-MiniLM-L6-v2`)
- **Sparse Retrieval (BM25-like)** â€” using SPLADE from FastEmbed
- **Hybrid Fusion** â€” combining dense & sparse using Reciprocal Rank Fusion (RRF)
- **Late Interaction Reranking** â€” with multilingual Jina cross-encoder
- **Per-user Filtering** â€” all results are filtered by a synthetic `user_id`
- **Visualization & Logging** â€” latency and score histograms, JSONL logs
- **Interactive UI** â€” via Jupyter widgets in `main_interface.ipynb`


---
## ğŸ“½ï¸ Demo

[Short Demo Recording](hybridsearch_demo.mp4) 
- 00:00-00:12 - test pipeline on local test database
- 00:12-00:18 - full pipeline on production database
- 00:18-00:42 - search notebook

## ğŸ§± Project Structure
```text
project-root/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                           â† ğŸ“¦ Loads YAML config
â”‚   â”œâ”€â”€ data_preparation.py                 â† ğŸ“¤ Upload dataset to Qdrant
â”‚   â”œâ”€â”€ evaluation.py                       â† ğŸ§ª Query execution & logging
â”‚   â”œâ”€â”€ hybrid_search.py                    â† ğŸ” Dense + sparse + RRF
â”‚   â”œâ”€â”€ reranker.py                         â† âš–ï¸ CrossEncoder reranking
â”‚   â””â”€â”€ visualize.py                        â† ğŸ“Š Matplotlib-based plotters (optiolal)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ TMDB_movie_dataset_v11_small.csv    â† ğŸ“¦ Test dataset 3,000 records
â”‚   â”œâ”€â”€ TMDB_movie_dataset_v11.csv          â† âŒ too big for github, shared on dropbox, link below
â”‚   â””â”€â”€ movies_backup.json                  â† âŒ too big for github, shared on dropbox, link below
â”‚
â”œâ”€â”€ config.yaml                             â† âš™ï¸ Central config (models, paths, params)
â”œâ”€â”€ requirements.txt                        â† ğŸ“¦ Reproducibility
â”œâ”€â”€ README.md                               â† ğŸ“˜ How to run, overview
â””â”€â”€ main_interface.ipynb                    â† ğŸ““ Central interactive notebook (user input, demo)
```
---

## ğŸ§ª Quickstart

### 1. Install dependencies (Python 3.10+)
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
### 2. Start Qdrant locally
```bash
docker-compose up -d
docker ps
docker logs qdrant-node1 -f
curl http://localhost:6333/cluster | jq

docker-compose down -v
```
Compose file: `deployment/docker-compose.yml`

### 3. Run the test pipeline. 3000 records takes ~4 min
```bash
python 0_test_pipeline.py
```
### 4. Run the complete pipeline. 1.2M records takes several hours depending on your compute
Download the dataset and update dataset_path in the config 
```bash
python 1_complete_pipeline.py
```
â±ï¸ Complete Pipeline run on g6.4xlarge, GPU enabled, 1.2M in 3.5 hours:

<img src="image-2.png" width="50%">

â±ï¸ Complete Pipeline run on Apple M3 Pro, 1.2M in 13.5 hours:

<img src="image.png" width="50%">

### 4. Explore the results interactively
Run search queries interactively in Jupyter Notebook
```bash
jupyter notebook 2_Main_Notebook.ipynb
```

### âš™ï¸ Configuration
Key options in `config.yaml`
`collection_name:`
`batch_size:`

`embedding_models:`

`qdrant:` - database endpoint

`dataset_path:`
`rows:` - set to desired number of rows i.e. 1000 for dev-mode. by default the complete pipeline will read the entire file.

### ğŸ“ Dataset
- âœ… 3000 row sample included in the distribution - data folder
- ğŸ“‚ [Full dataset in CSV](https://www.dropbox.com/scl/fo/i06gcqjmxk3z020j95wb2/AAgRqmImMWIV_EOvYwJeEVQ?rlkey=e6wacmtdj5txt27xhepjtu18x&st=c952zhtm&dl=0)
- ğŸ§  [Full collection snapshot](https://www.dropbox.com/scl/fo/i06gcqjmxk3z020j95wb2/AAgRqmImMWIV_EOvYwJeEVQ?rlkey=e6wacmtdj5txt27xhepjtu18x&st=c952zhtm&dl=0) 
- â„¹ï¸ [Source: TMDB Movies Dataset 2024 1.2M Movies](https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies)

### âœ… Requirements
Python = 3.10
Qdrant running locally (port 6333)

### ğŸ“ License
MIT â€” use freely, modify as needed. Contributions welcome!