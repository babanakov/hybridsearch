# ğŸ¬ Hybrid Search System for Movie Dataset

This project implements a modular hybrid search pipeline on a 1M-row TMDB movie dataset using Qdrant as the vector database. It combines dense (semantic), sparse (keyword), and reranking techniques to provide high-quality, user-specific search results.

Qdrant in Docker on Intel/AMD ():
---

## ğŸš€ Features

- **Dense Vector Search** â€” using SentenceTransformers (`all-MiniLM-L6-v2`)
- **Sparse Retrieval (BM25-like)** â€” using SPLADE from FastEmbed
- **Hybrid Fusion** â€” combining dense & sparse using Reciprocal Rank Fusion (RRF)
- **Late Interaction Reranking** â€” with multilingual Jina cross-encoder
- **Per-user Filtering** â€” all results are filtered by a synthetic `user_id`
- **Visualization & Logging** â€” latency and score histograms, JSONL logs
- **Interactive UI** â€” via Jupyter widgets in `main_interface.ipynb`

---

## ğŸ§± Project Structure
```text
project-root/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                           â† ğŸ“¦ Loads YAML config
â”‚   â”œâ”€â”€ data_preparation.py                 â† ğŸ“¤ Upload dataset to Qdrant
â”‚   â”œâ”€â”€ evaluation.py                       â† ğŸ§ª Query execution & logging
â”‚   â”œâ”€â”€ hybrid_search.py                    â† ğŸ” Dense + sparse + RRF
â”‚   â”œâ”€â”€ reranker.py                         â† âš–ï¸ CrossEncoder reranking
â”‚   â””â”€â”€ visualize.py                        â† ğŸ“Š Matplotlib-based plotters (optiolal)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ TMDB_movie_dataset_v11_small.csv    â† ğŸ“¦ Test dataset 3,000 records
â”‚   â”œâ”€â”€ TMDB_movie_dataset_v11.csv          â† ğŸ“¤ Full dataset 1,196,770 records
â”‚   â””â”€â”€ movies_backup.json                  â† ğŸ“¤ Full dataset processed, with embeddings
â”‚
â”œâ”€â”€ config.yaml                             â† âš™ï¸ Central config (models, paths, params)
â”œâ”€â”€ requirements.txt                        â† ğŸ“¦ Reproducibility
â”œâ”€â”€ README.md                               â† ğŸ“˜ How to run, overview
â””â”€â”€ main_interface.ipynb                    â† ğŸ““ Central interactive notebook (user input, demo)
```
---

## ğŸ§ª Quickstart

### 1. Install dependencies (Python 3.10+)
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
### 2. Start Qdrant locally
```bash
docker run -p 6333:6333 qdrant/qdrant
docker-compose up -d
docker ps
docker logs qdrant-node1 -f
curl http://localhost:6333/cluster | jq

docker-compose down -v
```
### 3. Run the test pipeline. 3000 records takes ~4 min
python test_pipeline.py

### 4. Explore the results interactively
jupyter notebook notebooks/main_interface.ipynb

### âš™ï¸ Configuration
config.yaml

### ğŸ“ Dataset
Datataset included in the distribution - data folder

Source: https://www.kaggle.com/datasets/asaniczka/tmdb-movies-dataset-2023-930k-movies
TMDB Movies Dataset 2024 1.2M Movies

### âœ… Requirements
Python >= 3.10

Qdrant running locally (port 6333)

### ğŸ“ License
MIT â€” use freely, modify as needed. Contributions welcome!